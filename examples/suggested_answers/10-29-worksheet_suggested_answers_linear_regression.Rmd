---
title: "Linear Regression Basics"
author: "your name"
date: "2024-10-24"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(openintro)
library(ggplot2)
if (!tinytex::is_tinytex()) {
  latex_installed <- Sys.which("tlmgr") != ""
  
  if (!latex_installed) {
    tinytex::install_tinytex()
  } else {
    message("A LaTeX distribution already exists on the system.")
  }
} # this ensures TinyTeX is installed only if no LaTeX distribution is found
library(tinytex)  # to knit to PDF
set.seed(2265)
```

## Math 2265 Chapter 8. Linear Regression

- Work as a group!
- You will need to replace `"ans"` or `your_answer` in the source code
- Update your name in L3
- Add your group members' name below; students may lose one point if Question 0 is unanswered
- Make sure you save and `knit` your work (to html or pdf) before submitting it to Canvas

---

### Goal

- Review the basic concepts in linear regression
  - Meaning of line fitting
    - Residuals
  - The $R$-value
- Next time we will learn/review
  - When not to use linear regression
    - Linearity
    - Nearly normal residuals
    - Constant variability
    - Independent observations
  - how to use an `R`-function to find the least squares line 

---

### Question 0. Who are your group members? (List their first names)

**Answer:** 

  1. `<name_1>`
  1. `<name_2>`

---

### If you need more time to get used to `Markdown`, use the `Visual` mode.

The icon is located in the upper-left corner next to `source`. 

---

### Correlation factor R

```{r}
# Set seed for reproducibility
set.seed(0)

# Initialize data frame with a single column of random values
df <- data.frame(x = rnorm(100))

# Function to generate data with a specified correlation
generate_correlated_data <- function(x, r) {
  y <- r * x + sqrt(1 - r^2) * rnorm(length(x))
  return(y)
}

# Target correlations
target_correlations <- c(0.33, 0.69, 0.98, 1.00, 0.08, -0.64, -0.92, -1.00)
# target_correlations <- sample(target_correlations, 4)

# Loop over each target correlation and add as a new column in df
for (r in target_correlations) {
  # Use the exact correlation value, including sign, in the column name
  col_name <- paste0("r_", gsub("\\.", "", as.character(r * 100)))
  df[[col_name]] <- generate_correlated_data(df$x, r)
}

# View the resulting data frame
head(df)

# Save the data frame to a file
write.csv(df, "correlated_datasets.csv", row.names = FALSE)
```

```{r}
# Load necessary libraries
library(ggplot2)
library(gridExtra)

# Read the combined data from the CSV file
df <- read.csv("correlated_datasets.csv")

target_correlations <- sample(c(2:9),4)

counter <- 1

# Loop over the selected column positions
for (i in target_correlations) {
  # Dynamically create variable name like df2, df3, etc., based on the column position
  var_name <- paste0("df", counter)
  
  # Assign the data frame to the dynamically created variable name
  assign(var_name, data.frame(x = df$x, y = df[, i]))
  counter <- counter + 1

}

# Check the created data frames
ls(pattern = "^df[0-9]+$")

# Load necessary libraries
library(ggplot2)
library(gridExtra)

# Initialize a list to store the plots
plots <- list()

# Loop through the four data frames (df1, df2, df3, and df4)
for (i in 1:4) {
  # Dynamically get each data frame by name
  df_name <- paste0("df", i)
  data <- get(df_name)
  
  # Create the scatter plot
  p <- ggplot(data, aes(x = x, y = y)) +
    geom_point(alpha = 0.6) +
    labs(title = df_name,
         x = "X",
         y = "Y") +
    coord_fixed() +  # Maintain a 1:1 aspect ratio
    theme_minimal()
  
  # Store the plot in the list
  plots[[i]] <- p
}

# Arrange all four plots in a single row
grid.arrange(grobs = plots, ncol = 4)
```
### Question

Without computing the R-values, list the data frames in the increasing order of their R-values

### Answer: "your_answer" 

---

Here is an example of computing the R-value of `df1`. 

```{r}
cor_df1 <- cor(x = df1$x, y = df1$y)
cor_df1
```

Compute the other R-values to confirm your answer.

```{r}
cor_df2 <- cor(x = df2$x, y = df2$y)
cor_df3 <- cor(x = df3$x, y = df3$y)
cor_df4 <- cor(x = df4$x, y = df4$y)
c(cor_df1, cor_df2, cor_df3, cor_df4)
```

### Linear Regression (best fit line)

We will use the function `lm` to find the best fitting line (use the first column for the intercept and slope), and sketch its graph. Here is an example for `df1`.

```{r}
model <- lm(y~x, data=df1)
summary(model); print(paste("R-squared from cor:", cor_df1^2))
```

```{r}
ggplot(data=df1, aes(x=x,y=y)) +
  geom_point() +
  geom_abline(intercept = -0.01505, slope = -0.59011, color='hotpink')
```

### Task 1

Compute the sum of square residuals and save it to the variable `my_rss`: (Refer to the last worksheet)

```{r} 
your_code
#
my_rss <- your_answer
```

---

### Task 2

Find the best fitting line for `df2`, sketch the scatter plot and the line, and compute the sum of the square residuals.

```{r}
# linear model
model2 <- lm(y~x, data = df2)
summary(model2)
```

```{r}
ggplot(data=df1, aes(x=x,y=y)) +
  geom_point() +
  geom_abline(intercept = -0.01505, slope = -0.59011, color='hotpink')
```

```{r} 
your_code
#
my_rss2 <- your_answer
```

### Share your work and help your group members before uploading your work to Canvas
