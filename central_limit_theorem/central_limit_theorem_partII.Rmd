---
title: "Sampling and the Central Limit Theorem Part II"
author: "your name"
date: "2024-11-07"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(openintro)
library(ggplot2)
if (!tinytex::is_tinytex()) {
  latex_installed <- Sys.which("tlmgr") != ""
  
  if (!latex_installed) {
    tinytex::install_tinytex()
  } else {
    message("A LaTeX distribution already exists on the system.")
  }
} # this ensures TinyTeX is installed only if no LaTeX distribution is found
library(tinytex)  # to knit to PDF
set.seed(2265)
```

## Math 2265 Chapter 5. Foundations for Inference
### Section 5.1 Point Estimates and Sampling Variability

- Work as a group!
- You will need to replace `"ans"` or `your_answer` in the source code
- Update your name in L3
- Add your group members' name below; students may lose points if Question 0 is unanswered
- Make sure you save and `knit` your work (to html or pdf) before submitting it to Canvas
- Please only submit your work if you attended the class and worked with other students; this is not an online course

---

### Goal

1. Understand the central limit theorem by example
1. Understand point estimates, standard errors, and the condidence interval

---

### Question 0. Who are your group members? (List their first names)

**Answer:** 

  1. `<name_1>`
  1. `<name_2>`
  1. `<name_3>`
  1. `<name_4>`

---

### If you need more time to get used to `Markdown`, use the `Visual` mode.

The icon is located in the upper-left corner next to `source`. 

---

# Normal distribution, Central Limit Theorem, Confidence Interval

This worksheet is to understand the phase such as "95% OF MEANS PROJECTED TO FALL IN THIS RANGE." In a nutshell, we want to guess the `mean of the population` from the `mean of a sample` with, often, 95% confidence. 

In the last worksheet, we created a population of size 50,000 consisting of "successes" and "fails" and took 2,000 samples of size 1,000 each. The task was to estimate the population proportion $p = 0.66$ based on the sample proportions (often denoted by $\hat{p}$. 

Summary:
- Population proportion $p = 0.xx$
- Each sample need not have the same proportion or the population proportion.
- However, their distribution follows a normal distribution:
  - This is the consequence of the central limit theorem. 
  - The mean of this distribution is close to the population proportion

Last time, we saw a question of "will the mean be closer to the population proportion and the standard deviation will be smaller if we take more samples". Be careful, there are two sizes:

- Size of each sample 
- Number of samples we take

We took 2,000 samples each of size 1,000. So the distribution of the sample proportions consist of 2,000 observations and its mean is an excellent estimate of the population proportion. 

In the following, we verify this experimentally by varing the number of samples we take with 
100, 500, 1,000, and 5,000. 

Note: We can execute the following with a `for` loop. But since it is not a programming course, we will be happy with executing it four times (copy and paste works). 

```{r}
# the first two lines randomize the probability
set.seed(1105)
probabilities <- runif(2)
probabilities <- probabilities / sum(probabilities)

# generate population of size 50,000 consisting of successes and fails
population <-sample(c("success", "fail"), 50000, replace = TRUE, prob=probabilities) 
head(population)
```

100 Samples
```{r}
number_of_samples <- 100
sample_means <- replicate(number_of_samples, table(sample(population, 1,000))["success"])
sample_means <- sample_means/number_of_samples
head(sample_means)
hist(sample_means)
```

100 Samples
```{r}
number_of_samples <- 100
sample_means <- replicate(number_of_samples, table(sample(population, 1,000))["success"])
sample_means <- sample_means/number_of_samples
head(sample_means)
hist(sample_means)
```

100 Samples
```{r}
number_of_samples <- 100
sample_means <- replicate(number_of_samples, table(sample(population, 1,000))["success"])
sample_means <- sample_means/number_of_samples
head(sample_means)
hist(sample_means)
```

100 Samples
```{r}
number_of_samples <- 100
sample_means <- replicate(number_of_samples, table(sample(population, 1,000))["success"])
sample_means <- sample_means/number_of_samples
head(sample_means)
hist(sample_means)
```

We can also vary each sample size while fixing the number of samples, say 1,000. 

1,000 Samples
```{r}
number_of_samples <- 1000
sample_means <- replicate(number_of_samples, table(sample(population, 50))["success"])
sample_means <- sample_means/number_of_samples
head(sample_means)
hist(sample_means)

add more.

---

The population proportion in the example above is based on a categorical variable. 
The central limit theorem applies for numerical variables too. 

Next time we will have an example where the population parameter is a numerical variable and how we can approximate the population mean by sample means. It will be essentially the sample where the population proportion is replaced by the population mean.

By the central limit theorem, we may estimate the population parameter with samples, in reality, it is not easy to take several samples. Often, we rely on few samples if not one. Point estimates are sample statistics. In the example above, the sample proportion $\hat{p}$ is a point estimate. Point estimates vary and almost never be the population parameter we are interested in. Hence it is often more reasonable making an interval around the point estimate. This interval is called the **confidence interval**. 


---


