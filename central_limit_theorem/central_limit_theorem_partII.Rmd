---
title: "Sampling and the Central Limit Theorem Part I"
author: "your name"
date: "2024-11-02"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(openintro)
library(ggplot2)
if (!tinytex::is_tinytex()) {
  latex_installed <- Sys.which("tlmgr") != ""
  
  if (!latex_installed) {
    tinytex::install_tinytex()
  } else {
    message("A LaTeX distribution already exists on the system.")
  }
} # this ensures TinyTeX is installed only if no LaTeX distribution is found
library(tinytex)  # to knit to PDF
set.seed(2265)
```

## Math 2265 Chapter 5. Foundations for Inference
### Section 5.1 Point Estimates and Sampling Variability

- Work as a group!
- You will need to replace `"ans"` or `your_answer` in the source code
- Update your name in L3
- Add your group members' name below; students may lose one point if Question 0 is unanswered
- Make sure you save and `knit` your work (to html or pdf) before submitting it to Canvas
- Please only submit your work if you attended the class and worked with other students; this is not an online course

---

### Goal

1. Understand the central limit theorem by example

---

### Question 0. Who are your group members? (List their first names)

**Answer:** 

  1. `<name_1>`
  1. `<name_2>`
  1. `<name_3>`
  1. `<name_4>`

---

### If you need more time to get used to `Markdown`, use the `Visual` mode.

The icon is located in the upper-left corner next to `source`. 

---

# Normal distribution, Central Limit Theorem, Confidence Interval

This worksheet is to understand the phase such as "95% OF MEANS PROJECTED TO FALL IN THIS RANGE." In a nutshell, we want to guess the `mean of the population` from the `mean of a sample` with, often, 95% confidence. 

In this note, we create population data and take (several) samples from it. Recall that the size of the population is "big," and its sample is reasonable. In our example, the population consists of 50,000 observations, and the samples are 1,000. We will choose between "success" and "fail" though it can be replaced by any categories with two unique values such as, head and tail, candidate A and candidate B.  

The variable population will serve as the population. We will randomly select 50,000 integers between 1 and 1,000 and save them to the variable population. Our goal is to guess the success and fail ratio of the population (population parameter) via sample means (sample statistics). 

```{r}
# the first two lines randomize the probability
probabilities <- runif(2)
probabilities <- probabilities / sum(probabilities)

# generate population of size 50,000 consisting of successes and fails
population <-sample(c("success", "fail"), 50000, replace = TRUE, prob=probabilities) 
head(population)
```

Let's take a sample of size 1,000 from the population and compute its mean.

```{r}
my_sample <- sample(population, 1000)
head(my_sample)
table(my_sample)
```
This means that among the 1,000 samples there are s number of successes and f number of fails. Since s+f = 1000, the ratio is nothing but s/1000. This is a sample statistics. Take a few more samples and let's compute the ratio by code.


```{r}
my_sample <- sample(population, 1000)
print(table(my_sample))
print(paste("p_hat =", table(my_sample)[2]/1000))
```
```{r}
my_sample <- sample(population, 1000)
print(table(my_sample))
print(paste("p_hat =", table(my_sample)[2]/1000))
```
**Question 1**: 

(a) What are your point estimates? 
  Answer:
  
(b) Are they all the same?
  Answer:
  
(c) What is your guess for the population proportion?
  Answer:

---

### The distribution of the sample proportions

**Question 2**: What distribution do the means of samples have? In other words, if we repeat taking the proportion of a sample, what is the distribution of the sample_means?

We can answer Question 2 experimentally. The R function `replicate` is helpful in this case. For instance, 

```{r}
replicate(2, table(sample(population, 1000)))
```
We want to do it many times, say, 1,000 times, and save the output into the variable `sample_means.`

```{r}
sample_means <- replicate(1000, table(sample(population, 100))[2])
sample_means <- sample_means/1000
head(sample_means)
```


Now, let's see its distribution. Here, we used `hist`, but you can get the same result with `ggplot` and `geom_histogram`.

```{r}
hist(sample_means)
```

The sample means vary, but it follows the normal distribution. It is reasonable to guess that the mean of the `sample_means` is close to the mean of the `population.` Let's check it. 

```{r}
mean(sample_means)
prop.table(table(population))
```
---

Stop here


They should be very close. Now also check the distribution of the population. 

hist(population)
# gf_histogram(~population)

Surprisingly, it has a uniform distribution. Indeed, the central limit theorem says that no matter what the population's distribution is, we will have the normal distribution for the sample mean. The mean of the sample means approximates the population mean (something we wanted to find!).

Here, we need to take a lot of samples to come to a conclusion. But say, for instance, surveys for an election cost way too much money and time to do. How much can we get from one sample? Of course, it is often not the correct answer, but how confident are we? 

Question 2: How much can the mean of a single sample tell us about the mean of the population?

We can continue with the previous example, but we will use something that is close to the real survey. We create a population variable consisting of characters "A" and "B" representing candidates "A" and "B." The goal is to approximate the voting ratio between "A" and "B" from a single sample. 

We will keep the population size at 50,000 and the sample size at 1,000. Since the code is similar, I won't go over the details. 

set.seed(1749)
population <-sample(c("A","B"), 50000, replace = TRUE) 
head(population)

sum(population=="A")/50000

Here, we are interested in the ratio of "A" in the population (we mostly want to know if "A" or "B" has the majority vote). 

Let's take a sample. 

survey <- sample(population, 1000)

tally(survey)

sum(survey == "A")/1000

So the proportion of "A" is the number under A divided by 1000. In my test case, this was the outcome, but it will change as we use random sampling.

```
tally(survey)

X
  A   B 
523 477
```

So the proportion is 523/1000 = 0.523 (or 52.3%). In our sample, "A" has the majority vote. Now we want to predict what proportion the population has from this information with 95% confidence. The following formula will do the job but we won't get into the detail. They work like what whiskers do in a box plot. 

Given `p = 0.523`, compute $$\sqrt{\frac{p(1-p)}{n}}.$$ Then, multiply it by `1.96`. That is with `p = 0.523`

$$
1.96 \cdot \sqrt{\frac{0.523\cdot 0.477}{1000}} \approx 0.0158 (1.58\%).
$$

Then the interval we get is $(0.523 - 0.0158, 0.523 + 0.0158) = (0.492, 0.554)$, meaning that if we conduct 100 surveys, then 96 times the proportion for "A" lies between 49.2% and 55.4%. Hence "A" is very likely to win. We can check it with our population data.

In my test case, I got

```
tally(population)

X
    A     B 
24865 25135 
#
24865/50000

0.4973
```

# 1.96 * sqrt expression
p = sum(survey == "A")/1000
wing <- 1.96 * sqrt((p * (1-p))/1000)

p - wing
p + wing

tally(population)

# Num of A / Total
sum(population=="A")/length(population) 

---

Everything together

# population <-sample(c("A","B"), 50000, replace = TRUE)
# With prob = c(0.55, 0.45) "A" is more likely to win
population <-sample(c("A","B"), 50000, replace = TRUE,  prob = c(0.55, 0.45))
survey <- sample(population, 1000)

# tally(survey)

p <- sum(survey == "A")/1000

cat(sprintf("Survey %.4f\n",p))

wing <- 1.96 * sqrt((p * (1-p))/1000)

lower_bound <- p - wing
upper_bound <- p + wing

cat(sprintf("Lower and upper bound for the 96%% confidence interval  (%.4f, %.4f)\n", lower_bound, upper_bound))

# tally(population)

# Num of A / Total
cat(sprintf("Actual (population) %.4f\n",sum(population=="A")/length(population)))
 


